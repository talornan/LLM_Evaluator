# LLM Evaluator: Unleash the Potential of Large Language Models ü™Ñ

## üìñ Project Description
**Stop wasting time on manual LLM evaluation! ‚è∞** LLM Evaluator automates everything - feed your prompts, choose models, and instantly get deep insights & comparisons across models and tasks.

### Here's what LLM Evaluator can do for you: ‚ö°

**Effortless Evaluation**: Feed your prompts, choose models, and instantly get deep insights and comparisons with key metrics like Fluency, Coherence, and Toxicity. ‚ú®

**Model Matchmaker**: Find the perfect LLM for your task by comparing responses across different models.

**Continuous Improvement**: Track progress over time, identify areas for improvement, and stay ahead of the curve.

**Tailored for Experts**: Whether you're a Prompt Engineer crafting winning prompts or a Model Developer optimizing performance, LLM Evaluator has tools for you.

### In addition to the above, here are some details about the evaluation metrics:

- **ROUGE Score**: Measures the overlap of n-grams between the generated text and reference text.
- **BLEU Score**: Evaluates the precision of n-grams in the generated text compared to the reference text.
- **Exact Match**: Checks if the generated text matches the reference text exactly.
- **CHRF Score**: Measures the character n-gram F-score between the generated text and the reference text.
- **Toxicity**: Detects the presence of harmful or offensive language in the response.

## LLM Evaluator is perfect for:

- **Prompt Engineers**: ‚ú® Create prompts, analyze performance, receive recommendations for improving prompts.‚ú®
- **Model Developers**: Analyze model performance, receive recommendations on which model to use for a specific prompt.

## Technologies: ‚úçÔ∏è

LLM Evaluator leverages a robust tech stack for seamless evaluation and insightful comparisons:

- **Frontend**: HTML, CSS (Built with Streamlit for rapid development)
- **Backend**: Python (FastAPI for a performant and flexible REST API)
- **Machine Learning**: Hugging Face Transformer library for efficient access and interaction with various LLMs
- **Database**: MySQL for storing prompts, responses, and evaluation results

## API Functionality: ‚ú®

- **Submit Prompts**: Send your prompts and specify desired LLM models through intuitive API calls.
- **Evaluation Results**: Retrieve comprehensive reports including key metrics like Fluency, Coherence, ROUGE, BLEU, Exact Match, CHRF, and Toxicity (leveraging Hugging Face evaluation functions).
- **Model Comparison**: Compare performance across different LLMs for informed decision-making.

**Ready to unleash the full potential of your LLMs?**
**Start your free trial today! ‚ú®**
